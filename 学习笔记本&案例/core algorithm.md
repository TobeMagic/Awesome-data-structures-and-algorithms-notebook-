##  数据结构必备经法

> **学习数据结构与算法的理由**

1. 大厂面试

比如 BAT、Google、Facebook，面试的时候都喜欢考算法、让人现场写代码。公司只能考察他们的基础知识是否牢固。社招就更不用说了，越是厉害的公司，越是注重考察数据结构与算法这类基础知识。相比短期能力，他们更看中你的长期潜力。

2. 业务开发性能优化

对于大部分业务开发来说，我们平时可能更多的是利用已经封装好的现成的接口、类库来堆砌、**翻译业务逻辑**，很少需要自己实现数据结构和算法。但是，不需要自己实现，并不代表什么都不需要了解。

如果不知道这些类库背后的原理，不懂得时间、空间复杂度分析，如何能用好、用对它们？存储某个业务数据的时候，你如何知道应该用 ArrayList，还是 Linked List 呢？调用了某个函数之后，你又该**如何评估代码的性能和资源的消耗呢？**

作为业务开发，我们会用到各种框架、中间件和底层系统，比如 Spring、RPC 框架、消息中间件、Redis 等等。在这些基础框架中，一般都揉和了很多基础数据结构和算法的设计思想。比如，我们常用的 Key-Value 数据库 Redis 中，里面的有序集合是用什么数据结构来实现的呢？为什么要用跳表来实现呢？为什么不用二叉树呢？
如果你能弄明白这些底层原理，你就能更好地使用它们。**即便出现问题，也很容易就能定位**。因此，掌握数据结构和算法，不管对于阅读框架源码，还是理解其背后的设计思想，都是非常有用的。

而在面对新的问题或者业务场景中，也能够设计更好的方案来解决问题

> 在平时的工作中，数据结构和算法的应用到处可见。我来举一个你非常熟悉的例子：如何实时地统计业务接口的 99% 响应时间？
> 你可能最先想到，每次查询时，从小到大排序所有的响应时间，如果总共有 1200 个数据，那第 1188 个数据就是 99% 的响应时间。很显然，每次用这个方法查询的话都要排序，效率是非常低的。但是，如果你知道“堆”这个数据结构，用两个堆可以非常高效地解决这个问题。

3. 提升代码水平（个人能力！）

达到开源水平的代码能力，高手之间的竞争其实就在细节。这些细节包括：你用的算法是不是够优化，数据存取的效率是不是够高，内存是不是够节省等等。这些累积起来，决定了一个框架是不是优秀。

何为编程能力强？代码的可读性好、健壮、还是扩展性好等等，**其中性能好坏起码是其中一个非常重要的评判标准**。而对代码的时间复杂度、空间复杂度分析才能写出高性能的代码

如果你在一家成熟的公司，或者 BAT 这样的大公司，面对的是千万级甚至亿级的用户，开发的是 TB、PB 级别数据的处理系统。性能几乎是开发过程中时刻都要考虑的问题。一个简单的 ArrayList、Linked List 的选择问题，就可能会产生成千上万倍的性能差别。这个时候，数据结构和算法的意义就完全凸显出来了。之前你可能需要费很大劲儿来优化的代码，需要花很多心思来设计的架构，用了数据结构和算法之后，很容易就可以解决了。

掌握了数据结构与算法，你看待问题的深度，解决问题的角度就会完全不一样。因为这样的你，就像是站在巨人的肩膀上，拿着生存利器行走世界。数据结构与算法，会为你的编程之路，甚至人生之路打开一扇通往新世界的大门。

### 核心数据结构与算法

> **核心学习数据结构与算法**

 10 个数据结构：`数组、链表、栈、队列`（线性表）、散列表、二叉树、堆、跳表、图、Trie树

10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法

- **算法**是求解问题的一系列计算步骤，用来将输入数据转换成输出结果 `从蛮力到策略`
- **数据结构**是数据的组织与存储：`从杂乱无章到井然有序`
- **算法 + 数据结构 = 程序**

> 对于每一种数据结构或算法学习它的**“来历”“自身的特点”“适合解决的问题”以及“实际的应用场景”**,千万不要被动地记忆，要多辩证地思考，多问为什么。如果你一直这么坚持做，你会发现，等你学完之后，写代码的时候就会不由自主地考虑到很多性能方面的事情，时间复杂度、空间复杂度非常高的垃圾代码出现的次数就会越来越少。你的编程内功就真正得到了修炼。

<img src="core%20algorithm.assets/MergedImages.png" alt="MergedImages" style="zoom:50%;" />

> 算法的基本要素：一是 **（对数据对象的）运算和操作** ，二是 **（算法的）控制结构**

运算和操作：算术运算、逻辑运算、关系运算、数据传输

控制结构：顺序、选择、循环

> 算法的特征：**输入 、输出 、确定性、有限性** （、可行性 ）

- 输入性：必须有0个或多个输入（待处理信息）
- 输出性：应有一个或多个输出（已处理信息）
- 确定性：组成算法的每条指令是清晰的、无歧义
- 有穷性：算法必须总能在执行有限步之后终止
- （可行性：算法中所有的操作都必须足够基本，使算法的执行者或阅读者明确其含义以及如何执行。）

> 好算法的特征：

- 正确性：符合语法、编译通过；
- 健壮性：能**辨别不合法的输入**并做适当的处理，不至于异常退出（崩溃）
- 可读性：**结构化 + 准确的命名 + 注释**
- 效率性：速度尽可能快；存储空间尽可能少

> 

### 时间复杂度&空间复杂度分析

事后统计分析： 把代码跑一遍，通过统计、监控，就能得到算法执行的时间和占用的内存大小。（局限性大）

#### 时间复杂度分析

时间复杂度表示法，体现整体算法随着规模增大的趋势表现，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。

> 1. 只关注循环最多的一段 代码
> 2. 加法原则：取量级最大的复杂度
> 3. 乘法原则：取量级结果最大的
>
> 其中算法复杂度运算规则如下：
>
> 1.  加法规则
>     O(f(n))+O(g(n))=O(max(f(n),g(n)))
>     O(f(n))+O(g(n))=O(f(n)+g(n))
>     如果g(n)=O(f(n))，则O(f(n))+O(g(n))=O( (f(n))
> 2.  乘法规则
>     O(f(n))*O(g(n))=O(f(n)*g(n))
>     O(c*f(n))=O(f(n))，c是一个正常数
> 3.  f(n)=O ( (f(n))

![Θ,O,Ω的图像表示](core%20algorithm.assets/20211016202335.jpeg)

1）渐近符号的含义：**O（上界）、Ω（下界）、Θ（准确界）** 

2）运行时间记号的定义(设有函数 f(n)和 g(n)是定义在非负整数集合上的正函数)：

> **大** **O** **记号**：存在正常数 c 和 n0 使得对所有n ≥ n0有：f(n) ≤ cg(n)，记为f(n) ∈ O(g(n))
>
> - 例如：n ∈O(n2)、100n+5 ∈O(n2)、n(n-1)/2 ∈O(n2)

> **大** **Ω** **记号**：存在正常数 c 和 n0 使得对所有n ≥ n0有：f(n) ≥ cg(n)，记为f(n) ∈ Ω(g(n))
>
> - 例如：n3∈Ω (n2)、n(n+1)∈Ω (n2)、4n2+5 ∈Ω (n2)

> **大Θ记号**：设有函数 f(n)和 g(n)是定义在非负整数集合上的正函数，如果存在正整数 n0和正常数c1 和 c2（c1 ≤c2），使得当 n≥n0 时，有 c1 g(n)≤f(n)≤c2 g(n) ，就称 f(n)的阶是 Θ(g(n))，则记做f(n)=Θ(g(n))

<img src="core%20algorithm.assets/image-20231225103903739.png" alt="image-20231225103903739" style="zoom: 67%;" />

> 时间复杂度具有「最差」、「平均」、「最佳」三种情况，分别使用 O , Θ , Ω 三种符号表示。此外还有均摊时间复杂度（amortized timecomplexity）。「`平均则是引入概率论，均摊则是平摊思想`」

**根据从小到大排列，常见的算法时间复杂度主要有：**

**`O(1) ＜ O(log n) ＜ O(n) ＜ O(nlog n) ＜ O(n^2) ＜ O(n^3) < O(2^n) ＜ O(n!) ＜ O(n^n)`**

主要分为两类，**多项式量级**和**非多项式量级**。

<img src="core%20algorithm.assets/image-20231128154326858.png" alt="image-20231128154326858" style="zoom: 33%;" />

最常见的多项式时间算法的渐近时间复杂度。
        `O(1)＜O(log n)＜O(n)＜O(nlog n)＜O(n2)＜O(n3)`

最常见的非多项式量级算法的渐近时间复杂度。当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是**非常低效**的算法。
        ` O(2n)＜O(n!)＜O(nn)`

![img](core%20algorithm.assets/20211016203924.png)

>  **渐进增长率比较**

方法1：**定义法**

找到正常数 c 和 n0 使得对所有n ≥ n0 有 f(n) ≤ cg(n)，则f(n) = O(g(n))

方法2：**极限法**

比较两个函数f(n)和g(n)的渐近增长率时，可以对两个函数相除，然后令变量 n 趋向于无穷，看这个极限值是无穷大还是一个大于零的常数还是趋向于0。

<img src="https://img.jwt1399.top/img/image-20211016205209274.png" alt="img" style="zoom:33%;" />

- 前两种情况意味着f(n) ∈ O(g(n))
- 后两种情况意味着f(n) ∈ Ω(g(n))
- 第二种情况意味着f(n) ∈ Θ(g(n))

方法3：**取对数法**

对于比较难的比较的两个函数，我们可以对它们同时取对数后再进行比较

`常见对数公式：`

- logam*n = logam + logan
- loga(m/n) = logam - logan
- logamn = nlogam
- logan√m = (1/n)logam
- logab = logcb / logca
- alogab = b

> 

参考文章：

https://jwt1399.top/posts/46989.html#toc-heading-9

####空间复杂度分析

空间复杂度分析：时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度全称就是渐进空间复杂度（asymptotic spacecomplexity），表示算法的存储空间与数据规模之间的增长关系。

查看循环最多的变量生成的一段代码

<img src="core%20algorithm.assets/image-20231128154541062.png" alt="image-20231128154541062" style="zoom:50%;" />

常见的复杂度并不多，从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n )。几乎都是这些

> 其中还有四种复杂度分析方法
>
> 最好情况时间复杂度（best case timecomplexity）、最坏情况时间复杂度（worst case time complexity）、
>
> 

1. 数组和字符串：
  
   - **数组操作**（插入、删除、查找等）
   
   >  前缀和算法 ：
   >
   >  1.  寻找数组的中心索引 （左边之和等于右边）（前缀和）
   >
   >  排序：
   >
   >  1.  搜索插入位置（查找相同值或插值） （二分查找）
   >  1.  [合并区间](https://leetcode.cn/problems/merge-intervals/) （排序 + 二维数组）
   >
   >  
   >
   >  十大排序
   
   - 字符串操作（反转、查找、匹配等）
   - 双指针技巧（快慢指针、滑动窗口等）
   
2. 链表：
   - 单链表和双链表的基本操作
   - 快慢指针技巧在链表中的应用
   - 链表反转、环检测等问题

3. 栈和队列：
   - 栈和队列的基本操作（入栈、出栈、入队、出队等）
   - 用栈解决的问题（括号匹配、逆波兰表达式等）
   - 用队列解决的问题（广度优先搜索等）

4. 哈希表：
   - 哈希表的原理和实现
   - 哈希函数的设计和冲突解决方法
   - 哈希表在查找和去重等问题中的应用

5. 树与图：
   - 二叉树的遍历（前序、中序、后序）
   - 二叉搜索树的性质和操作
   - 堆和优先队列的基本概念和应用
   - 图的表示方法和遍历算法（深度优先搜索、广度优先搜索）

6. 排序和搜索：
   - 常见排序算法（冒泡排序、插入排序、快速排序等）
   - 高级排序算法（归并排序、堆排序等）
   - 二分查找和其他搜索算法的实现和应用

7. 动态规划：
   - 动态规划的基本概念和解题思路
   - 斐波那契数列和背包问题等经典动态规划案例
   - 动态规划的优化技巧和常见变种

8. 贪心算法：
   - 贪心算法的基本思想和适用条件
   - 贪心算法的经典案例（任务调度、区间覆盖等）
   - 贪心算法与动态规划的比较和区别

9. 图算法：
   - 最短路径算法（Dijkstra算法、Bellman-Ford算法等）
   - 最小生成树算法（Prim算法、Kruskal算法等）
   - 拓扑排序和关键路径等问题

10. 高级数据结构：
    - 并查集的原理和应用
    - 字典树和前缀树的基本操作和应用
    - 线段树和树状数组的实现和应用

## 数据结构

### 线性表

<img src="core%20algorithm.assets/image-20231128190250563.png" alt="image-20231128190250563" style="zoom:50%;" />

与它相对立的概念是非线性表，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。

<img src="core%20algorithm.assets/image-20231128190420528.png" alt="image-20231128190420528" style="zoom:50%;" />

#### 数组

数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。由于数组有**连续的内存空间和相同类型的数据**,内存访问机制 - 任意访问(随机访问)

> 有这么一种说法,之所以数组下标从0开始, 是因为在内存访问机制中可以减少一次减号运算
>
> 从数组存储的内存模型上来看，“**下标”最确切的定义应该是“偏移（offset）**”。前面也讲到，如果用 a 来表示数组的首地址，a[0] 就是偏移为 0 的位置，也就是首地址，a[k] 就表示偏移 k 个 type_size 的位置，所以计算 a[k] 的内存地址只需要用这个公式：
>
> `a[k]_address = base_address + k * type_size`

与之对应的也有两个问题,插入数据和删除数据,需要移动大量的内存,而实际中的动态数组需要划出大量的内存块迁移,会导致内存碎片问题, 

> 在面对这个场景, JVM 标记清除垃圾回收算法的核心思想先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。

<img src="core%20algorithm.assets/image-20231128190517761.png" alt="image-20231128190517761" style="zoom:50%;" />

此外还要警惕数据越界问题,很多计算机病毒也正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统，所以写代码的时候一定要警惕数组越界。

> 数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。(也就是继续运行,你发现不了!!)

实际上,有很多容器已经被开发优化好,比如 Java 中的 ArrayList、C++ STL 中的vector。在项目开发中，ArrayList 最大的优势就是可以将很多数组操作的细节封装起来。比如前面提到的数组插入、删除数据时需要搬移其他数据等。另外，它还有一个优势，就是支持动态扩容(将空间自动扩容为 1.5 倍大小。)。不过，这里需要注意一点，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建 ArrayList 的时候事先指定数据大小。

1.Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。

2.如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。

对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。

### 链表

三种最常见的链表结构，它们分别是：单链表、双向链表和循环链表, 双向循环链表。由于链表性质, 一般不会出现内存碎片问题.

我们把内存块称为链表的“结点”。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。如图所示，我们把这个记录下个结点地址的指针叫作后继指针next。

数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，**预读**数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。

<img src="core%20algorithm.assets/image-20231128191817122.png" alt="image-20231128191817122" style="zoom:50%;" />

数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足（out of memory）”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。(当我们往支持动态扩容的数组中插入一个数据时，如果数组中没有空闲空间了，就会申请一个更大的空间，将数据拷贝过去，而数据拷贝的操作是非常耗时的。)

> 如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。

代码要写好链表有以下几点：

1. 了解理解指针或引用的含义（地址调用）
2. 警惕指针丢失和内存泄漏：特别是在删除操作中，避免丢失和未释放资源
3. 利用哨兵机制简化链表代码

## 算法

![image-20231225105424184](core%20algorithm.assets/image-20231225105424184.png)

常见的问题一般都为判断问题和优化问题

- **判断问题**：是否存在一个…解
- **优化问题**：找出**最大/最小**的…解

> 很多经典的难问题都是优化问题，而一个优化问题往往可以转换成对应的判断问题。

贪心算法：逐步建立一个解决方案，具体地优化一些局部准则。 自顶向下。

分治算法：将一个问题分解成独立的子问题，求解每个子问题，并将子问题的解组合起来形成原问题的解。 自顶向下。

动态规划：把一个问题分解成一系列相互重叠的子问题，并为越来越大的子问题建立解决方案。自底向上。

### 递归算法&分治算法

> 递归与分治的定义

**递归**：一个算法直接地或间接地调用自己本身，简称自己调用自己

【所能解决问题的特征】

可分解为一个或多个**相同**子问题，递归有限性（一定的递归次数），有界性（有结束递归的条件）

**分治**：将难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之。

【所能解决问题的特征】

（1）该问题的**规模缩小到一定的程度**就可以容易地解决；

（2）该问题可以分解为若干个规模较小的相同问题，即该问题具有**最优子结构性质**；

（3）利用该问题分解出的**子问题的解可以合并**为该问题的解；

（4）该问题所分解出的各个**子问题是相互独立**的，即子问题之间不包含公共的子问题。

> 递归与分治的算法思想

**递归法思想**：

通过函数调用自身将问题转化为本质相同但规模较小的子问题，是分治策略的具体体现。

**分治法思想**：

将一个规模为 n 的问题分解为 k 个规模较小的子问题，这些子问题互相独立且与原问题相同。

递归地解这些子问题，然后将各子问题的解合并得到原问题的解，自底向上逐步求出原来问题。

> 1）分治法的基本步骤：
>
> （1）划分：将原问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题；
>
> （2）求解子问题：若子问题规模较小而容易被解决则直接解，否则递归地解各个子问题；
>
> （3）合并：将各个子问题的解合并为原问题的解。
>
> 2）分治法的启发式规则（原则）
>
> （1）**平衡子问题**：最好使子问题的规模大致相同。
>
> （2）**独立子问题**：各子问题之间相互独立

#### 递归的复杂性分析
> 方法1：**主定理-递推方程求解**

主定理适用于求右边递归式算法的时间复杂度：**T(n) = aT(n/b) + f(n)**

其中：

- n：问题的规模大小
- a：原问题的子问题个数
- n/b：每个子问题的大小
- f(n)：将原问题分解成子问题和将子问题的解合并成原问题的解的时间

![image-20231226140437826](core%20algorithm.assets/image-20231226140437826.png)

方法2：**递归树方法（Recursion Tree）**

在递归树中每一个节点表示一个单一子问题的代价，子问题对应某次递归函数的调用。我们将树中每层中的代价求和，得到每层的代价，然后将所有层的代价求和，得到所有递归调用的总代价。

以mergeSort为例：

$T(N)=2T(N/2) + \Theta(N)$
假设$\Theta(N)=aN$

<img src="core%20algorithm.assets/image-20231226140816742.png" alt="image-20231226140816742" style="zoom:50%;" />

树的高度为$logN$
每层代价为$aN$
可得总代价=$aN(logN)$
根据Big-O定理，可得$T(N)=O(Nlog(N))$

例子：

<img src="core%20algorithm.assets/image-20231226145913563.png" alt="image-20231226145913563" style="zoom: 33%;" />

#### 经典算法

经典算法如下：

<img src="core%20algorithm.assets/image-20231226143849657.png" alt="image-20231226143849657" style="zoom:67%;" />

<img src="core%20algorithm.assets/image-20231226144007170.png" alt="image-20231226144007170" style="zoom:67%;" />

![image-20231226144029881](core%20algorithm.assets/image-20231226144029881.png)

还有快速算法、大数乘法（分治求解，减少乘法次数）等等，以下为经典算法的时间复杂度。

![image-20231226144354146](core%20algorithm.assets/image-20231226144354146.png)

> 重点补充
>
> 1）快速排序算法的性能
>
> 快速排序算法的效率与 轴值的选择 和 划分子序列的平衡性 有关
>
> 快速排序算法的性能取决于 **划分的对称性**
>
> 2）各问题求解时所用方法或算法
>
> 递归：排列问题，整数划分问题，Hanoi 塔问题
>
> 分治策略：二分搜索技术，大整数乘法，矩阵乘法，棋盘覆盖，合并排序，快速排序，线性时间选
>
> 择，最接近点对问题，循环赛日程表。
>
> 【例题 1】快速排序算法是基于 `分治策略 `的一种排序算法。
>
> 【例题 2】从分治法的一般设计模式可以看出，用它设计出的程序一般是` 递归算法` 。

### 动态规划

动态规划问题分析是自顶而下的思路，但是算法实现却是自底而上的策略。

动态规划与分治法类似，都是把大问题拆分成小问题，通过寻找大问题与小问题的递推关系，解决一个个小问题，最终达到解决原问题的效果。

但不同的是，分治法在子问题和子子问题等上被重复计算了很多次，而动态规划则具有记忆性，通过填写表把所有已经解决的子问题答案纪录下来，在新问题里需要用到的子问题可以直接提取，避免了重复计算，从而节约了时间，所以在问题满足最优性原理之后，用动态规划解决问题的核心就在于填表，表填写完毕，最优解也就找到。

> **本章重点：**
>
> - 理解动态规划算法的思想。
> - 对相应问题能建立基本的递归关系式并用从底至上的方法来求解，在求解过程中知道如何建立数据储存的表格。
> - 重点掌握的问题：带权重的活动安排问题、**0-1背包问题**、**最长公共子序列问题**、**矩阵连乘的最优计算次序问题**。
> - 理解0-1背包问题的动态规划算法不是多项式时间算法。

> 动态规划算法的基本步骤

（1）找出最优解的性质，并刻画其结构特征。

（2）递归地定义最优值。

（3）以自底向上的方式计算出最优值。

（4）根据计算最优值时得到的信息，构造最优解。

> 动态规划的算法思想

将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解，

【适用条件】**分解得到的子问题往往不是相互独立的**

> 动态规划算法的基本要素

动态规划算法的两个基本要素是. **最优子结构性质** 和 **重叠子问题性质**

> 动态规划法的变形： **备忘录方法**
>
> 【区别】动态规划算法是 **自底向上** ，备忘录方法（和递归）算法的是 **自顶向下** 。
>
> 动态规划每个子问题都要解一次，但不会求解重复子问题；备忘录方法只解哪些确实需要解的子问题；递归方法每个子问题都要解一次，包括重复子问题。

#### 经典算法

##### 矩阵连乘问题

> 矩阵连乘的计算次数与计算顺序的关系

假设有一个p*q规模的矩阵A，一个q*r规模的矩阵B，并且我们现在再加上一个规模为r*s的矩阵C，那么这三个矩阵的乘积ABC有两种计算顺序：

 （AB）C
   A（BC）

对于第一种计算顺序来说，总共需要的计算次数为：

因为AB共需要计算【p*q*r】次，并且生成一个规模为【p*r】的中间矩阵，这个中间矩阵再与矩阵C相乘，又需要计算【p*r*s】次，并且生成一个规模为【p*s】的矩阵，这个矩阵也就是最后的结果，因此，按照第一种顺序计算，一共需要的计算次数如下：

$mult[(AB)C] = pqr+prs$

同理，按照第二种计算顺序，我们一共需要计算下面这么多次：

$mult[A(BC)] = qrs+pqs$

假设p=5,q=4,r=6并且s=2，则：

![img](core%20algorithm.assets/20190730111806740.png)

按照第一种计算顺序，我们需要计算180次，而按照第二种计算顺序，我们只需要计算88次就够了！！但是这两种顺序计算出来的矩阵的值却始终是一样的，真是太神奇了，计算顺序竟然能够影响所需要的计算次数，**因此，对于矩阵连乘来说，计算顺序是非常重要的！**

> **问题描述：**给定 n 个矩阵 {A1,A2,…,An} ，其中 Ai 与 Ai+1 是可乘的，用加括号的方法表示矩阵连乘的次序，不同加括号的方法所对应的计算次序是不同的，求矩阵连乘的最佳计算次序。
>
>
> 问题需要我们找出最少的计算次数，就是需要我们找到“正确”的计算顺序！

1. **分析最优子结构**，在本问题中，即找出如何划分“括号”的方法。

将矩阵连乘的积 **Ai Ai+1 … Aj** 简记为`A[i][j]` ，**Ai** 的维度记为 **pi-1 × pi**，那么上述问题变为求解 `A[1][n]`的最佳计算次序。

`A[1][n]的最佳计算次序：`设这个计算次序在矩阵 AK (1≤k<n) 和 AK+1 之间将矩阵链断开，则相应的加括号方式：( **Ai Ai+1 … Ak** )( **Ak+1Ai+1 … An** )，依此计算顺序，总计算量为 **Ai Ai+1 … Ak** 的计算量加上 **Ak+1Ai+1 … An** 的计算量，再加上 ( **Ai Ai+1 … Ak** ) 和 ( **Ak+1Ai+1 … An** )相乘的计算量。即 **`A[1][n] = A[1][k] + A[k+1][n] + pi-1 pk pn`**

> 此时问题的“最优子结构”就已经出现了，为了保证Ai...k*Ak+1...j是最优的计算顺序，则Ai...k和AK+1...j也应该是由“最优计算顺序”计算出来的，因此，我们就可以递归的调用这个过程。
> 假设Ai...k的计算顺序并不是最优的，那么我们可以用更好的计算顺序去替换，这样就产生了悖论。
> 同样的，如果Ak+1...j并不是最优的，那么我们可以在找出另外一个更好的计算顺序来替换他，此时也产生了悖论。

2.**建立最优子结构的递推式**

设计算 `A[i][j]` (i≤j) 所需的最少乘法次数为 `m[i][j]`，那么得到以下的递推公式（最少乘积次数则为【Ai...k所需要的最少乘积次数】+【Ai+1...j所需要的最少乘积次数】+【中间生成的两个临时矩阵所需要的乘积次数】）：

![img](core%20algorithm.assets/20190730222401675.png)

3. **自底向上计算最优质**

K的可能值也只有j-i种，因此我们就把这j-i都一个个的去试一遍，然后找出m[i,j]最小的那一个情况，此时的K值就是我们需要的，并且最小乘积次数也找到了，就是m[i,j]次。

计算m[i,j]时，我们必须首先得把![img](core%20algorithm.assets/20190731001913900.png)和![img](core%20algorithm.assets/20190731001924521.png)

给计算出来，才能够顺利的把![img](core%20algorithm.assets/2019073100200185.png)给计算出来。

对于被分割的两个子序列，对应的矩阵链的长度都小于![img](core%20algorithm.assets/2019073100222159.png)

因此，我们的算法以矩阵链长度增长的顺序来计算，就像下面这样子（假设我们需要计算m[1,n]）：

![img](core%20algorithm.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE5NzgyMDE5,size_16,color_FFFFFF,t_70.png)

例如，要计算矩阵连乘积A1A2A3A4A5A6，其中各矩阵的维数分别为:

| A1    | A2    | A3   | A4   | A5    | A6    |
| :---- | :---- | :--- | :--- | :---- | :---- |
| 30x35 | 35x15 | 15x5 | 5x10 | 10x20 | 20x25 |

依据递推公式，按照图 a 的次序，计算出 `m[i][j]`

![img](core%20algorithm.assets/image-20211011130742451.png)

![img](https://img.jwt1399.top//img/20211011131609.png)

本题是求解 `A[1][6]` 的最佳计算次序，即求`m[1][6]` 。由图 b 可知， `m[1][6] =15125`，因此矩阵连乘积A1A2A3A4A5A6 的最优值为 **15125**

4. **构造`最优解`**

若将对应`m[i][j]`的断开位置`k`记为`s[i][j]`，计算出最优值`m[i][j]`后，可递归地由`s[i][j]`[][]构造出相应的最优解。



![img](core%20algorithm.assets/20211011131648.png)



**例如**，**`m[2][5] = m[2][3] + m[4][5] + p1p3p5`** ，则 k = 3，因此 **`s[2][5] = 3`**

★最优解：

`s[1][6] = 3` ,因此矩阵链在A3和A4之间断开，则加括号方式为 **(A1A2A3)(A4A5A6 )**

`s[1][3] = 1`,因此矩阵链在A1和A2之间断开，则加括号方式为 **(A1(A2A3))(A4A5A6 )**

`s[4][6] = 5,`因此矩阵链在A5和A6之间断开，则加括号方式为 **(A1(A2A3))((A4A5)A6 )**

因此最优解为 **(A1(A2A3))((A4A5)A6 )**

```c++
#include <iostream>
using namespace std;
#define N 100
int s[N][N], m[N][N];  //s存储切割位置，m存储最优值 

void MatricChain(int *p , int n) {//p矩阵维数数组，n为矩阵个数
    for (int i = 1; i <= n; i++) {//初始化，对角线上的计算量和加括号的位置为0
        m[i][i] = 0;
        s[i][i] = 0;
    }
    for (int r = 2; r <= n; r++) {//r为矩阵链的长度
        for (int i = 1; i <= n - r + 1; i++) { //i为首矩阵的序号
            int j = i + r - 1; //j为尾矩阵的序号
            m[i][j] = m[i][i] + m[i + 1][j] + p[i - 1] * p[i] * p[j];//首先尝试在矩阵 i 处分开
            s[i][j] = i;
            for (int k = i + 1; k < j; k++) {  
                    int t = m[i][k] + m[k + 1][j] + p[i - 1] * p[k] * p[j]; // 然后尝试在矩阵 k 处分开 (i<=k<j)
                    if (t < m[i][j]) {
                        m[i][j] = t;
                        s[i][j] = k;
                    }
            }
        }
    }
}
void Traceback(int i, int j) {
    if (i == j) {
        return;
    }
    int k = s[i][j];
    Traceback(i, k); 
    Traceback(k + 1, j);
    cout << "A" << "[" << i << ":" << k << "]" << "×" << "A""[" << (k + 1) << ":" << j << "]"<<"  " ;
}

int main(){
    int p[] = {30,35,15,5,10,20,25};//矩阵维数
    int n = sizeof(p) / sizeof(int) - 1;//矩阵个数

    for(int i = 0; i < n; i++){
        cout << p[i]<<"×"<<p[i+1]<<"  ";
    }
    cout << "这" << n << "个矩阵连乘的最优值和最优解？" << endl;
    cout << endl;

    MatricChain(p,n);
    cout << "m[i][j]:" << endl;
    for (int i = 1; i <= n; i++) {
        for (int j = 1; j <= n; j++)
            cout << m[i][j] << "\t";
        cout << endl;
    }

    cout << endl;
    cout << "s[i][j]:" << endl;
    for (int i = 1; i <= n; i++) {
        for (int j = 1; j <= n; j++)
            cout << s[i][j] << "\t";
        cout << endl;
    }
    cout << endl;
    cout << "最少连乘次数(最优值):" << m[1][n] << "次。" << endl;
    cout << "最佳计算次序(最优解):" ;
    Traceback(1, n);
    cout << endl;
}
```

![img](core%20algorithm.assets/20211011231627.png)

##### 最长公共子序列

**问题描述︰**给定两个字符串，求解这两个字符串的最长公共子序列(LCS)。如: X={1,5,2,8,9,3,6},Y={5,6,8,9,3,7}，其最长公共子序列为{5,8,9,3}，最长公共子序列长度为4。那么如何求解呢？

[1143. 最长公共子序列 - 力扣（Leetcode）](https://leetcode.cn/problems/longest-common-subsequence/description/?envType=study-plan-v2&id=top-100-liked)

**1、分析最优子结构**

设序列 **X={x1, x2, …, xi}** 和 **Y={y1, y2, …, yj}** 的最长公共子序列为 **Z={z1, z2, …, zk}**，则

- ①若 **xi=yj** ，则 zk=xi=yj 且 **Zk-1** 是 Xi-1 和 Yj-1 的最长公共子序列;
- ②若 **xi≠yj** 且 **zk≠xi** ，则 **Zk** 是 Xi-1 和 Yj 的最长公共子序列;.
- ③若 **xi≠yj** 且 **zk≠yj** ，则 **Zk **是 Xi 和 Yj-1 的最长公共子序列。

**2、建立递推公式**

用**`c[i][j]`**表示 **Xi={x1, x2, …, xi}** 和 **Yj={y1, y2, …, yj}** 的最长公共子序列的长度，那么得到以下的递推公式：



![img](core%20algorithm.assets/20211010182558.png)

**3、计算`最优值`**

> 假设 X={A,B,C,E} 和 Y={B,D,C,E}

根据上方递推公式得到下表：

| `c[i][j]` | 1B   | 2D   | 3C   | 4E   |
| :-------- | :--- | :--- | :--- | :--- |
| **1A**    | 0    | 0    | 0    | 0    |
| **2B**    | 1    | 1    | 1    | 1    |
| **3C**    | 1    | 1    | 2    | 2    |
| **4E**    | 1    | 1    | 2    | `3`  |

在 `C[2][0]` 处，j = 0 ，此时根据公式`C[2][0]= 0`

在 `C[2][1]` 处，B = B，即 **xi=yj** ，此时根据公式`C[2][1]=C[1][0]+1=0+1=1`

在 `C[2][2]` 处，B ≠ C，即 **xi≠yj** ，此时根据公式`C[2][2]=max{C[2][1],C[1][2]}=1`

根据最**右下角的值(`c[][]`)**，我们可以知道**最长公共子序列长度为3**。

**4、构造`最优解`**

`b[i][j]`记录`c[i][j]`的值是由哪个子问题的解得到的

- `if(X[i]==Y[j])` 用b=1代表
- `if(X[i]!=Y[j])` 用b=2代表

| `b[i][j]` | 1B   | 2D   | 3C   | 4E   |
| :-------- | :--- | :--- | :--- | :--- |
| **1A**    | 2    | 2    | 2    | 2    |
| **2B**    | 1    | 2    | 2    | 2    |
| **3C**    | 2    | 2    | 1    | 2    |
| **4E**    | 2    | 2    | 2    | 1    |

| `c[i][j]` | 1B   | 2D   | 3C   | 4E   |
| :-------- | :--- | :--- | :--- | :--- |
| **1A**    | 0    | 0    | 0    | 0    |
| **2B**    | 1`↖` | 1`←` | 1    | 1    |
| **3C**    | 1    | 1    | 2`↖` | 2    |
| **4E**    | 1    | 1    | 2    | 3`↖` |

`↖`处则为最长公共子序列{B,C,E}

##### 0-1背包问题

> **问题描述：**有n个物品，它们有各自的重量 wi 和价值 vi ，现有给定容量为 C 的背包，如何让背包里装入的物品具有最大的价值总和？

**1、分析最优子结构**

定义一个参数：`OPT(i,w)`

`OPT(i,w)`表示表示前 i 个物品 ( 1,2,3,…,i )的最大价值，i（当前背包存放物品的数量）、w（当前背包容量）

OPT(i,w) 显然有两种方案：

- ①不选择 i 物品
  - 如果不选择 i 物品，原问题退化成 **OPT(i-1，w)**，即包的剩余容量比 i 物品重量小，装不下，此时的价值与前 i-1 个的价值是一样的，从(1,2,3…i-1)中找最优解
- ②选择 i 物品
  - 如果选择 i 物品，原问题退化成 **vi + OPT(i-1，w-wi)**，即既然选择了 i 物品，能装的重量减少 wi，并尝试 i-1 是否装入

**2、建立递推公式**

递推公式如下：



![img](core%20algorithm.assets/202111111714615.png)



**3、计算`最优值`、构造`最优解`**

例如：给定如下 5 个物品的价值 vi 和重量 wi，限制包的容量 C 为11



![img](core%20algorithm.assets/202111111714596.png)



依据递推公式，计算出`OPT(i,w)`



![img](core%20algorithm.assets/202111111714543.png)



OPT(2,2) = max{ v2 + OPT(1,2-w2)，OPT(1,2)} = max{6，1} = 6

…

OPT(3,5) = max{ v3 + OPT(2,5-w3)，OPT(2,5)} = max{18，7} = 18

OPT(4,11) = max{ v4 + OPT(3,11-w4)，OPT(3,11)} = max{40，25} = 40

OPT(5,11) = max{ v5 + OPT(4,11-w5)，OPT(4,11)} = max{35，40} = 40

**因此最大价值为 40，由图中红线回溯可知，背包装了物品 3 和 4**

代码实现如下

```c
#include <iostream>
#include <iomanip>															//setw()函数
using namespace std;

typedef struct ITEM {
    int wight;													//单个物品的重量
    int value;													//单个物品的价值
}ITEM_INFO;

void creatItemInfo(ITEM_INFO *items, int itemNum)//创建背包物品基本信息
{
    cout << "请输入(value weigh),例如(1 1)" << endl;
    for (unsigned int i = 0; i < itemNum; i++)
    {
        cout << "Enter item " << i + 1 << " information: ";
        cin >> items[i].value >> items[i].wight;
    }
}

void PrintItemInfo(ITEM_INFO *items, int itemNum)
{
    for (unsigned int i = 0; i < itemNum; i++)
    {
        cout << "Item" << i + 1 << ":\t" << items[i].value << "\t" << items[i].wight << "\t" << endl;
    }
}

void DynamicKnapsack(ITEM_INFO *items, int** m, int maxWeight, int itemNum)//用动态规划解决0/1背包问题
{
    //其实首先是将m[0, ],第一行清零，由于之前全清零了，所以就没做这步了

    for (unsigned int i = 1; i <= itemNum; i++)											//i:物品的数量，从1到itemNum
    {
        for (unsigned int w = 0; w <= maxWeight; w++)									//w:背包的当前重量，最开始没有物品为0，慢慢增加到maxWeight
        {
            //分两种情况，(1)i号物品不放入背包；(2 else)i号物品放入背包
            if (items[i - 1].wight > w) {
                m[i][w] = m[i - 1][w];
            }
            else {
                //OPT(i,w) <== OPT(i-1, w) ? Vi+OPT(i-1, w-wi)
                if (m[i - 1][w] > items[i - 1].value + m[i - 1][w - items[i - 1].wight])
                    m[i][w] = m[i - 1][w];
                else
                    m[i][w] = items[i - 1].value + m[i - 1][w - items[i - 1].wight];
            }
        }
    }
}


int g_i = 0;			//返回活动j存在path中
void FindSolution(ITEM_INFO *items, int** m, int i, int w, int* path)//回溯求解问题的解
{
    if (i == 0 || w == 0)
        return;
    else if (m[i - 1][w] < items[i - 1].value + m[i - 1][w - items[i - 1].wight])	//当w=0,不能执行这里了，重量已经0，还减少？越界，所以不加m==0判断，下面执行出错误
    {
        //i物品选中，迭代时候数量i减一，背包能容量的重量减wi
        path[g_i++] = i;
        return FindSolution(items, m, i - 1, w - items[i - 1].wight, path);			//这里是items[i - 1]，因为第一个物品信息存放在0号内存单元的
    }
    else
        //i物品没选中，迭代时候数量i减一即可
        return FindSolution(items, m, i - 1, w, path);
}


int main()
{
    int itemNum = 0;														//物品的数量
    int maxWeight = 0;														//背包最大能放的重量
    cout << "物品个数:";
    cin >> itemNum;
    cout << "背包容量：";
    cin >> maxWeight;

    ITEM_INFO *items = new ITEM_INFO[itemNum];

    creatItemInfo(items, itemNum);
    //PrintItemInfo(items, itemNum);
    
    //其实m[][]是(itemNum+1)*(maxWeight+1),要多一行一列
    int **m = new int*[maxWeight+1];
    for (unsigned int i = 0; i < itemNum+1; i++)
        m[i] = new int[maxWeight + 1];
    for (unsigned int i = 0; i < itemNum+1; i++)
        for (unsigned int j = 0; j < maxWeight +1; j++)
            m[i][j] = 0;

    DynamicKnapsack(items, m, maxWeight, itemNum);

    cout << "\nm[][]:\n";
    for (unsigned int i = 0; i <= itemNum; i++)
    {
        for (unsigned int j = 0; j <= maxWeight; j++)
            cout << m[i][j] << setw(6);
        cout << "\n";
    }

    int* path = new int[itemNum];													//存储任务的数组
    for (int i = 0; i < itemNum; ++i)
        path[i] = 0;

    FindSolution(items, m, itemNum, maxWeight, path);

    cout << "\n最大权重物品：";
    for (unsigned int i = 0; i < itemNum && path[i] != 0; i++)
        cout << path[i] << "  ";

    //释放内存
    for (unsigned int i = 0; i < itemNum; i++)
        delete[] m[i];
    delete[] m;
    delete[] items;
    delete[] path;
    return 0;
}
```



![img](core%20algorithm.assets/202111111713603.png)



 01背包是NP

> 理解0-1背包问题的动态规划算法不是多项式时间算法。

P 是否等于 NP 是计算复杂度理论里面最著名的未解决的问题之一，一个 NP 完全问题，如果能找到解决它的多项式时间算法，那么就说明了 P = NP。

如今 0-1 背包问题已经被证明是 NP 完全问题，而它却有着一个动态规划解法，该解法有着 O(n*W) 的时间复杂度，其中 n 是物品的个数，W 是背包限制的最大负重。所以时间复杂度对输入 n，W 来说是多项式时间的，所以说明了 NP = P 是不是哪里出错了呢？

其实多项式时间是相对于输入规模来说的，输入规模最直观的理解就是输入到该算法的数据占了多少比特内存。0-1 背包的输入有 n 个物品的价值，n 个物品的重量，还有背包的最大负重 W。如今假设 W 占用的比特数为 L（也就是说背包的最大负重的输入规模是 L），那么 log(W) = L，所以 O(n*W) = O(n*2L)，由此看到，该算法的时间复杂度对于输入规模 L 来说是指数级别的，随着输入规模 L 的增加，运算时间会迅速增长。

实际上，人们把这种动态规划的算法称为伪多项式时间算法（pseudo-polynomial time algorithm），这种算法不能真正意义上实现多项式时间内解决问题。

参考文章：

https://blog.csdn.net/qq_19782019/article/details/94356886

https://jwt1399.top/posts/46989.html#toc-heading-57

### 贪心算法

贪心算法就是用计算机模拟一个「贪心的人」来做出决策。这个贪心的人是目光短浅的，他每次总是：

- 只做出**当前看来最好的选择**
- **只看眼前的利益，而不考虑做出选择后对未来造成的影响**
- 并且他一旦做出了选择，就**没有办法反悔**（不可回溯）

`总结：`在对问题求解时，总是做出在**当前最好的选择**。也就是说并**不从整体最优考虑**，他所做出的是在某种意义上的**局部最优解**。 因此贪心算法不是对**所有问题**都能得到整体最优解。

